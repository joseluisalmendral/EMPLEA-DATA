{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identificamos skills tecnológicas a través de las descripciones laborales\n",
    "## Intro\n",
    "#### Mediante un asistente creado en la [OpenAI developer platform](https://platform.openai.com/) vamos a extraer de las descripciones laborales, la información que queremos con el formato que he indicado al asistente, en este caso un JSON.\n",
    "\n",
    "#### Esto (mediante entrenamiento) nos ahorra problemas como:\n",
    "- Tecnologías escritas de diferente forma. (PowerBi, Power BI o Powerbi por ejemplo)\n",
    "- El idioma de las descripciones.\n",
    "- Filtros enormes que habría que hacer para el tratamiento de texto (tildes, mayusculas, etc).\n",
    "\n",
    "\n",
    "### Formato del Json resultante\n",
    "<img src=\"../recursos/json_extraido_por_model_ETL.png\" height=\"500px\">\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importamos librerías y configuraciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "tqdm.pandas()\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creamos diccionario de dataframes con las ofertas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ofertas_data_analyst', 'ofertas_data_engineer', 'ofertas_data_scientist', 'ofertas_seguridad_privacy_data'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_dfs_ofertas = {archivo.rstrip('.csv') : pd.read_csv(f'../datos/datos_recibidos_empresa/{archivo}') for archivo in os.listdir('../datos/datos_recibidos_empresa/') if archivo.endswith('.csv')}\n",
    "\n",
    "dic_dfs_ofertas.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conectamos con api OpenAI y realizamos la extracion de skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_openai = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "# asistente creado y entrenado en el playground de la api\n",
    "asistente_extractor = api_openai.beta.assistants.retrieve(os.getenv('ASSISTANT_API_KEY'))\n",
    "\n",
    "\n",
    "def extraer_skills_descripcion(descripcion):\n",
    "    \"\"\"\n",
    "    Función para extraer habilidades a partir de una descripción utilizando un asistente de OpenAI.\n",
    "    Por cada ejecución se crea una nueva conversacion para no tener que mantener el contexto de la conversación,\n",
    "    siendo más eficiente a nivel de tokens y pero menos eficiente a nivel de codigo.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Crear una nueva conversación\n",
    "        try:\n",
    "            conversacion = api_openai.beta.threads.create()\n",
    "        except Exception as e:\n",
    "            print(f\"Error al crear la conversación: {e}\")\n",
    "            return ['Error al iniciar la conversación']\n",
    "\n",
    "        # Enviar el mensaje del usuario al hilo de conversación\n",
    "        try:\n",
    "            mensaje = api_openai.beta.threads.messages.create(\n",
    "                thread_id=conversacion.id,\n",
    "                role=\"user\",\n",
    "                content=descripcion\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error al enviar el mensaje: {e}\")\n",
    "            return ['Error al enviar el mensaje']\n",
    "\n",
    "        # Ejecutar y esperar la respuesta del asistente\n",
    "        try:\n",
    "            ejecucion_asistente = api_openai.beta.threads.runs.create_and_poll(\n",
    "                thread_id=conversacion.id,\n",
    "                assistant_id=asistente_extractor.id\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error durante la ejecución del asistente: {e}\")\n",
    "            return ['Error durante la ejecución del asistente']\n",
    "\n",
    "        # Verificar el estado de la ejecución\n",
    "        if ejecucion_asistente.status == 'completed':\n",
    "            try:\n",
    "                # Obtener todos los mensajes del hilo\n",
    "                mensajes = api_openai.beta.threads.messages.list(\n",
    "                    thread_id=conversacion.id\n",
    "                )\n",
    "                # Procesar la respuesta del asistente\n",
    "                respuesta = ast.literal_eval(mensajes.data[0].content[0].text.value)\n",
    "                return respuesta['skills'] if respuesta else ['Desconocidas']\n",
    "            except Exception as e:\n",
    "                print(f\"Error al procesar la respuesta: {e}\")\n",
    "                return ['Error al procesar la respuesta']\n",
    "        else:\n",
    "            # Si el estado no fue completado, devolver el estado como mensaje\n",
    "            print(f\"Estado de la ejecución: {ejecucion_asistente.status}\")\n",
    "            return ['Estado no completado']\n",
    "\n",
    "    except Exception as e:\n",
    "        # Capturar cualquier error inesperado\n",
    "        print(f\"Error inesperado: {e}\")\n",
    "        return ['Error inesperado']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obteniendo info: OFERTAS_DATA_ANALYST\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estado de la ejecución: failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estado de la ejecución: failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 450/450 [33:44<00:00,  4.50s/it]\n",
      " 25%|██▌       | 1/4 [33:44<1:41:14, 2024.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obteniendo info: OFERTAS_DATA_ENGINEER\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estado de la ejecución: failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estado de la ejecución: failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 450/450 [33:19<00:00,  4.44s/it]\n",
      " 50%|█████     | 2/4 [1:07:04<1:06:59, 2009.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obteniendo info: OFERTAS_DATA_SCIENTIST\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 450/450 [34:42<00:00,  4.63s/it]\n",
      " 75%|███████▌  | 3/4 [1:41:47<34:03, 2043.25s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obteniendo info: OFERTAS_SEGURIDAD_PRIVACY_DATA\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estado de la ejecución: failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 450/450 [35:25<00:00,  4.72s/it]\n",
      "100%|██████████| 4/4 [2:17:13<00:00, 2058.27s/it]\n"
     ]
    }
   ],
   "source": [
    "for key, value in tqdm(dic_dfs_ofertas.items()):\n",
    "    print(f'Obteniendo info: {key.upper()}\\n')\n",
    "\n",
    "    df = value\n",
    "    df['Skills'] = df['Descripcion'].progress_map(lambda x: extraer_skills_descripcion(x))\n",
    "\n",
    "    df.to_csv(f'../datos/datos_recibidos_empresa/datos_skills_identificadas/{key}_identificadas.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
