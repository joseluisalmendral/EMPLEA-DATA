{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pymongo.mongo_client import MongoClient\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pickle  # Para guardar el vectorizador\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conexion realizada con exito!\n"
     ]
    }
   ],
   "source": [
    "uri = f\"mongodb+srv://root:{os.getenv('DB_PASS')}@cluster0.pse9r.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\"\n",
    "\n",
    "cliente_db = MongoClient(uri)\n",
    "\n",
    "# Send a ping to confirm a successful connection\n",
    "try:\n",
    "    cliente_db.admin.command('ping')\n",
    "    print(\"Conexion realizada con exito!\")\n",
    "\n",
    "    db = cliente_db[os.getenv('DB_NAME')]\n",
    "    coleccion = db[os.getenv('DB_COLECTION')]\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraer todas las skills de la base de datos\n",
    "# cursor = coleccion.find({}, {\"Skills\": 1, \"_id\": 0})\n",
    "# all_skills = [\" \".join(doc[\"Skills\"]).lower() for doc in cursor]  # Convertir listas en strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Inicializar el vectorizador TF-IDF\n",
    "# vectorizer = TfidfVectorizer(lowercase=True)\n",
    "\n",
    "# # Entrenar el vectorizador con todas las skills de la BD\n",
    "# tfidf_matrix = vectorizer.fit_transform(all_skills)\n",
    "\n",
    "# # Guardar el vectorizador en disco para futuras consultas\n",
    "# with open(\"tfidf_vectorizer.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(vectorizer, f)\n",
    "\n",
    "# print(\"Vectorizador TF-IDF entrenado y guardado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Función para vectorizar una oferta con TF-IDF\n",
    "# def vectorizar_skills(offer_skills, vectorizer):\n",
    "#     offer_text = \" \".join(offer_skills).lower()  # Convertir lista en texto\n",
    "#     return vectorizer.transform([offer_text]).toarray()[0].tolist()  # Convertir a lista\n",
    "\n",
    "# # Procesar todas las ofertas y almacenar los vectores en MongoDB\n",
    "# for offer in tqdm(coleccion.find(), desc='Vectorizando ofertas... '):\n",
    "#     offer_vector = vectorizar_skills(offer[\"Skills\"], vectorizer)\n",
    "#     coleccion.update_one({\"_id\": offer[\"_id\"]}, {\"$set\": {\"Skills_vectorizadas\": offer_vector}})\n",
    "\n",
    "# print(\"Vectorización de ofertas completada y almacenada en MongoDB.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Titulo': 'Information Security Consultant', 'Skills': ['iso 27001'], 'Descripcion': 'En SecureFlow Corp, buscamos un/a Information Security Consultant apasionado/a por la protección y seguridad de la información, que quiera unirse a nuestro equipo en Barcelona, España. Tu principal misión será garantizar la confidencialidad, integridad y disponibilidad de los datos, implementando medidas de seguridad efectivas y asegurando el cumplimiento normativo, como ISO 27001 o GDPR. Requisitos mínimos incluyen 3-5 años de experiencia en el sector y conocimientos avanzados en tecnologías como Trabajo en equipo, Comunicación efectiva, Análisis crítico, ISO 27001. Ofrecemos un entorno dinámico, salario competitivo y formación continua para mantenerte a la vanguardia en privacidad y seguridad de datos.', 'Similitud': 0.71}\n",
      "{'Titulo': 'Data Protection Officer', 'Skills': ['gdpr', 'iso 27001'], 'Descripcion': 'En SecureFlow Corp, buscamos un/a Data Protection Officer apasionado/a por la protección y seguridad de la información, que quiera unirse a nuestro equipo en Sevilla, España. Tu principal misión será garantizar la confidencialidad, integridad y disponibilidad de los datos, implementando medidas de seguridad efectivas y asegurando el cumplimiento normativo, como ISO 27001 o GDPR. Requisitos mínimos incluyen 3-5 años de experiencia en el sector y conocimientos avanzados en tecnologías como Análisis crítico, Conocimiento de GDPR, Comunicación efectiva, ISO 27001. Ofrecemos un entorno dinámico, salario competitivo y formación continua para mantenerte a la vanguardia en privacidad y seguridad de datos.', 'Similitud': 0.58}\n",
      "{'Titulo': 'Security Risk Management Expert', 'Skills': ['gdpr', 'iso 27001'], 'Descripcion': 'En DataDefense Inc, buscamos un/a Security Risk Management Expert apasionado/a por la protección y seguridad de la información, que quiera unirse a nuestro equipo en Sevilla, España. Tu principal misión será garantizar la confidencialidad, integridad y disponibilidad de los datos, implementando medidas de seguridad efectivas y asegurando el cumplimiento normativo, como ISO 27001 o GDPR. Requisitos mínimos incluyen Al menos 5 años de experiencia en el sector y conocimientos avanzados en tecnologías como Comunicación efectiva, Conocimiento de GDPR, Trabajo en equipo, ISO 27001. Ofrecemos un entorno dinámico, salario competitivo y formación continua para mantenerte a la vanguardia en privacidad y seguridad de datos.', 'Similitud': 0.58}\n",
      "{'Titulo': 'Cybersecurity & Compliance Analyst', 'Skills': ['gdpr', 'iso 27001'], 'Descripcion': 'En SecureFlow Corp, buscamos un/a Cybersecurity & Compliance Analyst apasionado/a por la protección y seguridad de la información, que quiera unirse a nuestro equipo en Valencia, España. Tu principal misión será garantizar la confidencialidad, integridad y disponibilidad de los datos, implementando medidas de seguridad efectivas y asegurando el cumplimiento normativo, como ISO 27001 o GDPR. Requisitos mínimos incluyen Al menos 5 años de experiencia en el sector y conocimientos avanzados en tecnologías como Análisis crítico, Trabajo en equipo, Conocimiento de GDPR, ISO 27001. Ofrecemos un entorno dinámico, salario competitivo y formación continua para mantenerte a la vanguardia en privacidad y seguridad de datos.', 'Similitud': 0.58}\n",
      "{'Titulo': 'Data Privacy Specialist Junior', 'Skills': ['iso 27001', 'gdpr'], 'Descripcion': 'En PrivacyGuard Labs, buscamos un/a Data Privacy Specialist Junior apasionado/a por la protección y seguridad de la información, que quiera unirse a nuestro equipo en Bilbao, España. Tu principal misión será garantizar la confidencialidad, integridad y disponibilidad de los datos, implementando medidas de seguridad efectivas y asegurando el cumplimiento normativo, como ISO 27001 o GDPR. Requisitos mínimos incluyen 1-2 años de experiencia en el sector y conocimientos avanzados en tecnologías como Trabajo en equipo, Comunicación efectiva, Análisis crítico, ISO 27001. Ofrecemos un entorno dinámico, salario competitivo y formación continua para mantenerte a la vanguardia en privacidad y seguridad de datos.', 'Similitud': 0.58}\n"
     ]
    }
   ],
   "source": [
    "# Cargar el vectorizador previamente guardado\n",
    "with open(\"tfidf_vectorizer.pkl\", \"rb\") as f:\n",
    "    vectorizer = pickle.load(f)\n",
    "\n",
    "# Función para recomendar ofertas\n",
    "def recommend_jobs(user_skills, vectorizer, collection, top_n=5):\n",
    "    # Vectorizar las skills del usuario con TF-IDF\n",
    "    user_text = \" \".join(user_skills).lower()\n",
    "    user_vector = vectorizer.transform([user_text]).toarray()\n",
    "\n",
    "    # Extraer todas las ofertas con sus vectores almacenados\n",
    "    offers = list(collection.find({}, {\"_id\": 1, \"Titulo\": 1, \"Descripcion\": 1, \"Skills\": 1, \"Skills_vectorizadas\": 1}))\n",
    "    \n",
    "    # Convertir los vectores de las ofertas en una matriz NumPy\n",
    "    offer_vectors = np.array([offer[\"Skills_vectorizadas\"] for offer in offers])\n",
    "\n",
    "    # Calcular similitud coseno entre usuario y ofertas\n",
    "    similarities = cosine_similarity(user_vector, offer_vectors)[0]\n",
    "    \n",
    "    # Ordenar ofertas por similitud\n",
    "    sorted_offers = sorted(zip(offers, similarities), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Devolver las N mejores ofertas\n",
    "    top_offers = sorted_offers[:top_n]\n",
    "    return [{\"Titulo\": offer[\"Titulo\"], \"Skills\": offer['Skills'], \"Descripcion\": offer['Descripcion'], \"Similitud\": round(sim, 2)} for offer, sim in top_offers]\n",
    "\n",
    "# Probar con un usuario\n",
    "user_skills = ['iso']\n",
    "recommended_jobs = recommend_jobs(user_skills, vectorizer, coleccion)\n",
    "\n",
    "# Mostrar resultados\n",
    "for job in recommended_jobs:\n",
    "    print(job)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### version mejorada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': '6799f4092cee2337199c9aad', 'Similitud': 0.51}\n",
      "{'_id': '6799f4092cee2337199c9baa', 'Similitud': 0.51}\n",
      "{'_id': '6799f4092cee2337199c9bae', 'Similitud': 0.51}\n",
      "{'_id': '6799f40b2cee2337199c9dc6', 'Similitud': 0.47}\n",
      "{'_id': '6799f40b2cee2337199c9ddc', 'Similitud': 0.47}\n"
     ]
    }
   ],
   "source": [
    "# Cargar el vectorizador previamente guardado\n",
    "with open(\"tfidf_vectorizer.pkl\", \"rb\") as f:\n",
    "    vectorizer = pickle.load(f)\n",
    "\n",
    "# Función para recomendar un número específico de ofertas ordenadas por similitud\n",
    "def recommend_jobs(user_skills, vectorizer, collection, top_n=10, similarity_threshold=0.30):\n",
    "    # Vectorizar las skills del usuario con TF-IDF\n",
    "    user_text = \" \".join(user_skills).lower()\n",
    "    user_vector = vectorizer.transform([user_text]).toarray()\n",
    "\n",
    "    # Extraer solo los IDs y los vectores de habilidades de las ofertas\n",
    "    offers = list(collection.find({}, {\"_id\": 1, \"Skills_vectorizadas\": 1}))\n",
    "\n",
    "    # Convertir los vectores de las ofertas en una matriz NumPy\n",
    "    offer_vectors = np.array([offer[\"Skills_vectorizadas\"] for offer in offers])\n",
    "\n",
    "    # Calcular similitud coseno entre usuario y ofertas\n",
    "    similarities = cosine_similarity(user_vector, offer_vectors)[0]\n",
    "\n",
    "    # Filtrar y ordenar ofertas por similitud\n",
    "    matching_offers = sorted(\n",
    "        [{\"_id\": str(offer[\"_id\"]), \"Similitud\": round(sim, 2)}\n",
    "         for offer, sim in zip(offers, similarities) if sim > similarity_threshold],\n",
    "        key=lambda x: x[\"Similitud\"], reverse=True\n",
    "    )\n",
    "\n",
    "    # Devolver solo las 'top_n' ofertas más similares\n",
    "    return matching_offers[:top_n]\n",
    "\n",
    "# Probar con un usuario\n",
    "user_skills = ['r', 'machine learning', 'sql', 'azure', 'nosql', 'data visualization', 'bi', 'python']\n",
    "recommended_jobs = recommend_jobs(user_skills, vectorizer, coleccion, top_n=5)\n",
    "\n",
    "# Mostrar resultados\n",
    "for job in recommended_jobs:\n",
    "    print(job)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('6799f4092cee2337199c9aad'), 'Titulo': 'Business Intelligence Analyst', 'Empresa': 'Trend Analytics', 'Ubicacion': 'Zaragoza, España', 'Salario': ['50.000', '70.000'], 'Experiencia minima': 'Al menos 5 años', 'Tipo de contrato': 'Indefinido, jornada completa', 'Estudios minimos': ['Grado en Estadística', ' Matemáticas', ' Informática o similar'], 'Skills': ['python', 'sql', 'bi'], 'Descripcion': \"En Trend Analytics, nos encontramos en la búsqueda de un/a Business Intelligence Analyst para unirte a nuestro equipo ubicado en Zaragoza, España. Este puesto ofrece la oportunidad de trabajar en proyectos innovadores, con impacto directo en la estrategia y la toma de decisiones de nuestra empresa. Como parte de tu trabajo, utilizarás tus habilidades en Python, SQL, Comunicación, BI para analizar datos complejos, identificar patrones y proporcionar insights clave para el negocio. Estamos especialmente interesados en profesionales con experiencia en Python, SQL, Comunicación, BI. Estas habilidades te permitirán abordar desafíos técnicos y colaborar con diferentes equipos para optimizar procesos y garantizar la calidad de los resultados. Para este puesto, buscamos candidatos con al menos Al menos 5 años de experiencia profesional, junto con una formación académica mínima de Grado en Estadística, Matemáticas, Informática o similar. Ofrecemos un atractivo paquete salarial en el rango de 50.000€ - 70.000€ brutos anuales y Indefinido, jornada completa, que asegura tanto estabilidad como flexibilidad para nuestros empleados. En nuestra empresa, promovemos un entorno inclusivo que valora la diversidad, fomenta el aprendizaje continuo y apoya el crecimiento profesional de cada miembro del equipo. Somos una organización dinámica que busca aprovechar al máximo el potencial de los datos para impulsar nuestra estrategia empresarial. Si buscas un rol desafiante que combine análisis de datos, colaboración interdisciplinar y oportunidades de desarrollo, ¡te animamos a postularte! En {row['Empresa']}, valoramos tu talento y dedicación, y estamos deseando conocerte.\", 'Referencia': 'DA00258', 'cat_original': 'Data Analyst', 'cat_identificada': 'Ninguna', 'fecha': '2024-11-16 00:00:00'}\n",
      "{'_id': ObjectId('6799f4092cee2337199c9baa'), 'Titulo': 'Python Data Analyst', 'Empresa': 'DataFlow Corp', 'Ubicacion': 'Madrid, España', 'Salario': ['28.000', '35.000'], 'Experiencia minima': 'Sin experiencia', 'Tipo de contrato': 'Proyecto, freelance', 'Estudios minimos': ['Grado en Estadística', ' Matemáticas', ' Informática o similar'], 'Skills': ['python', 'sql', 'bi'], 'Descripcion': \"En DataFlow Corp, nos encontramos en la búsqueda de un/a Python Data Analyst para unirte a nuestro equipo ubicado en Madrid, España. Este puesto ofrece la oportunidad de trabajar en proyectos innovadores, con impacto directo en la estrategia y la toma de decisiones de nuestra empresa. Como parte de tu trabajo, utilizarás tus habilidades en Python, SQL, Comunicación, BI para analizar datos complejos, identificar patrones y proporcionar insights clave para el negocio. Estamos especialmente interesados en profesionales con experiencia en Python, SQL, Comunicación, BI. Estas habilidades te permitirán abordar desafíos técnicos y colaborar con diferentes equipos para optimizar procesos y garantizar la calidad de los resultados. Para este puesto, buscamos candidatos con al menos Sin experiencia de experiencia profesional, junto con una formación académica mínima de Grado en Estadística, Matemáticas, Informática o similar. Ofrecemos un atractivo paquete salarial en el rango de 28.000€ - 35.000€ brutos anuales y Proyecto, freelance, que asegura tanto estabilidad como flexibilidad para nuestros empleados. En nuestra empresa, promovemos un entorno inclusivo que valora la diversidad, fomenta el aprendizaje continuo y apoya el crecimiento profesional de cada miembro del equipo. Somos una organización dinámica que busca aprovechar al máximo el potencial de los datos para impulsar nuestra estrategia empresarial. Si buscas un rol desafiante que combine análisis de datos, colaboración interdisciplinar y oportunidades de desarrollo, ¡te animamos a postularte! En {row['Empresa']}, valoramos tu talento y dedicación, y estamos deseando conocerte.\", 'Referencia': 'DA00061', 'cat_original': 'Data Analyst', 'cat_identificada': 'Ninguna', 'fecha': '2024-08-19 00:00:00'}\n",
      "{'_id': ObjectId('6799f4092cee2337199c9bae'), 'Titulo': 'Data Quality Analyst', 'Empresa': 'Metric Masters', 'Ubicacion': 'Córdoba, España', 'Salario': ['50.000', '70.000'], 'Experiencia minima': 'Al menos 5 años', 'Tipo de contrato': 'Temporal, media jornada', 'Estudios minimos': ['Grado en Estadística', ' Matemáticas', ' Informática o similar'], 'Skills': ['python', 'sql', 'bi'], 'Descripcion': \"En Metric Masters, nos encontramos en la búsqueda de un/a Data Quality Analyst para unirte a nuestro equipo ubicado en Córdoba, España. Este puesto ofrece la oportunidad de trabajar en proyectos innovadores, con impacto directo en la estrategia y la toma de decisiones de nuestra empresa. Como parte de tu trabajo, utilizarás tus habilidades en Python, SQL, Comunicación, BI para analizar datos complejos, identificar patrones y proporcionar insights clave para el negocio. Estamos especialmente interesados en profesionales con experiencia en Python, SQL, Comunicación, BI. Estas habilidades te permitirán abordar desafíos técnicos y colaborar con diferentes equipos para optimizar procesos y garantizar la calidad de los resultados. Para este puesto, buscamos candidatos con al menos Al menos 5 años de experiencia profesional, junto con una formación académica mínima de Grado en Estadística, Matemáticas, Informática o similar. Ofrecemos un atractivo paquete salarial en el rango de 50.000€ - 70.000€ brutos anuales y Temporal, media jornada, que asegura tanto estabilidad como flexibilidad para nuestros empleados. En nuestra empresa, promovemos un entorno inclusivo que valora la diversidad, fomenta el aprendizaje continuo y apoya el crecimiento profesional de cada miembro del equipo. Somos una organización dinámica que busca aprovechar al máximo el potencial de los datos para impulsar nuestra estrategia empresarial. Si buscas un rol desafiante que combine análisis de datos, colaboración interdisciplinar y oportunidades de desarrollo, ¡te animamos a postularte! En {row['Empresa']}, valoramos tu talento y dedicación, y estamos deseando conocerte.\", 'Referencia': 'DA00065', 'cat_original': 'Data Analyst', 'cat_identificada': 'Ninguna', 'fecha': '2024-10-05 00:00:00'}\n",
      "{'_id': ObjectId('6799f40b2cee2337199c9dc6'), 'Titulo': 'Machine Learning Specialist', 'Empresa': 'Infinite Data Labs', 'Ubicacion': 'Granada, España', 'Salario': ['60.000', '70.000'], 'Experiencia minima': 'Al menos 4 años', 'Tipo de contrato': 'Indefinido, jornada completa', 'Estudios minimos': ['Ciclo Formativo Grado Superior en Informática'], 'Skills': ['r', 'deep learning', 'data visualization', 'big data'], 'Descripcion': 'En Infinite Data Labs, estamos buscando un/a Machine Learning Specialist para unirse a nuestro equipo y trabajar en proyectos innovadores en el campo de la ciencia de datos. Con sede en Granada, España, este rol ofrece una oportunidad única para aplicar tus habilidades y conocimientos en tecnologías como R, Deep Learning, Data Visualization, Big Data, generando un impacto real en nuestros productos y servicios.\\n\\nComo parte de nuestro equipo, tendrás la responsabilidad de desarrollar soluciones basadas en datos, desde el análisis exploratorio hasta la implementación de modelos de Machine Learning, asegurando la calidad y escalabilidad de las mismas. Colaborarás con equipos multidisciplinares y trabajarás en un entorno ágil para optimizar procesos y generar insights accionables.\\n\\nRequisitos:\\n- Experiencia mínima: Al menos 4 años.\\n- Formación académica: Ciclo Formativo Grado Superior en Informática.\\n- Conocimiento técnico: R, Deep Learning, Data Visualization, Big Data.\\n\\nOfrecemos:\\n- Contrato: Indefinido, jornada completa.\\n- Salario competitivo: 60.000€ - 70.000€ Bruto/año.\\n- Ambiente de trabajo inclusivo y orientado al desarrollo profesional.\\n\\nSi buscas un entorno dinámico donde aplicar tus conocimientos y contribuir al desarrollo de soluciones innovadoras, ¡te invitamos a unirte a nuestro equipo en Infinite Data Labs!', 'Referencia': 'E6EC0A51', 'cat_original': 'Data Scientist', 'cat_identificada': 'Ninguna', 'fecha': '2024-09-09 00:00:00'}\n",
      "{'_id': ObjectId('6799f40b2cee2337199c9ddc'), 'Titulo': 'AI Solutions Architect', 'Empresa': 'Quantum Metrics', 'Ubicacion': 'Bilbao, España', 'Salario': ['No Dispobible'], 'Experiencia minima': 'Al menos 4 años', 'Tipo de contrato': 'Por obra o servicio, jornada completa', 'Estudios minimos': ['Máster en Data Science'], 'Skills': ['r', 'deep learning', 'data visualization', 'big data'], 'Descripcion': 'En Quantum Metrics, estamos buscando un/a AI Solutions Architect para unirse a nuestro equipo y trabajar en proyectos innovadores en el campo de la ciencia de datos. Con sede en Bilbao, España, este rol ofrece una oportunidad única para aplicar tus habilidades y conocimientos en tecnologías como R, Deep Learning, Data Visualization, Big Data, generando un impacto real en nuestros productos y servicios.\\n\\nComo parte de nuestro equipo, tendrás la responsabilidad de desarrollar soluciones basadas en datos, desde el análisis exploratorio hasta la implementación de modelos de Machine Learning, asegurando la calidad y escalabilidad de las mismas. Colaborarás con equipos multidisciplinares y trabajarás en un entorno ágil para optimizar procesos y generar insights accionables.\\n\\nRequisitos:\\n- Experiencia mínima: Al menos 4 años.\\n- Formación académica: Máster en Data Science.\\n- Conocimiento técnico: R, Deep Learning, Data Visualization, Big Data.\\n\\nOfrecemos:\\n- Contrato: Por obra o servicio, jornada completa.\\n- Salario competitivo: Salario no disponible.\\n- Ambiente de trabajo inclusivo y orientado al desarrollo profesional.\\n\\nSi buscas un entorno dinámico donde aplicar tus conocimientos y contribuir al desarrollo de soluciones innovadoras, ¡te invitamos a unirte a nuestro equipo en Quantum Metrics!', 'Referencia': '732769DF', 'cat_original': 'Data Scientist', 'cat_identificada': 'Ninguna', 'fecha': '2024-12-04 00:00:00'}\n"
     ]
    }
   ],
   "source": [
    "from bson import ObjectId\n",
    "\n",
    "# Función para recuperar ofertas completas excluyendo 'Skills_vectorizadas'\n",
    "def get_job_details_by_ids(job_ids, collection):\n",
    "    # Convertir los IDs a ObjectId si es necesario\n",
    "    object_ids = [ObjectId(job[\"_id\"]) for job in job_ids]\n",
    "    \n",
    "    # Consultar la base de datos excluyendo 'Skills_vectorizadas'\n",
    "    jobs = list(collection.find({\"_id\": {\"$in\": object_ids}}, {\"Skills_vectorizadas\": 0}))\n",
    "\n",
    "    return jobs\n",
    "\n",
    "# Probar la función con los IDs obtenidos de la recomendación\n",
    "job_details = get_job_details_by_ids(recommended_jobs, coleccion)\n",
    "\n",
    "# Mostrar resultados\n",
    "for job in job_details:\n",
    "    print(job)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
